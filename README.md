# Enterprise Document Intelligence Assistant

This project is a Retrieval Augmented Generation (RAG) based AI document Q&A system. It allows users to upload PDF documents, ask questions about their content, and receive answers generated by an AI model (Google Gemini), with documents and embeddings managed by Pinecone. The system includes an API backend built with FastAPI, an optional interactive web UI built with Streamlit, and monitoring capabilities via Weights & Biases. The application is designed to be containerized using Docker.

## Features

- **Document Q&A**: Ask natural language questions about your PDF documents
- **RAG Pipeline**: Utilizes a Retrieval Augmented Generation pipeline for contextually relevant answers
- **PDF Processing**: Ingests, chunks, and embeds PDF documents
- **Scalable Vector Storage**: Uses Pinecone for efficient storage and retrieval of document embeddings
- **AI Powered**: Leverages Google Gemini series models for embeddings and text generation
- **FastAPI Backend**: Provides a robust API for Q&A functionality
- **Streamlit UI (Optional)**: An interactive web interface for document uploads and Q&A
- **Dockerized**: Fully containerized for consistent deployment and scalability
- **Monitoring**: Integrated with Weights & Biases for tracking API calls and performance

## Technologies Used

- **Programming Language**: Python 3.8+
- **Core AI/ML Framework**: LangChain
- **LLM & Embeddings**: Google Gemini (via langchain-google-genai)
- **Vector Database**: Pinecone
- **API Framework**: FastAPI
- **Web UI Framework (Optional)**: Streamlit
- **Containerization**: Docker
- **Monitoring**: Weights & Biases (wandb)
- **Environment Management**: python-dotenv
- **PDF Processing**: pypdf

## Project Structure (Key Files)

```
.
├── docs/                     # Directory for sample/uploaded PDF documents
├── .env.example              # Example environment file (DO NOT COMMIT ACTUAL .env FILE)
├── .gitignore                # Specifies intentionally untracked files that Git should ignore
├── Dockerfile                # Docker configuration for the application
├── README.md                 # This file
├── main_api.py               # FastAPI backend application
├── requirements.txt          # Python dependencies
├── ui_app.py                 # Streamlit UI application (if implemented)
└── ...                       # Other configuration or script files
```

## Prerequisites

Before you begin, ensure you have the following installed/configured:

- **Python**: Version 3.8 or higher
- **Git**: For cloning the repository
- **Docker Desktop**: For building and running Docker containers

### API Keys & Accounts Required

- **Pinecone Account**:
  - API Key
  - Environment/Region (e.g., us-east-1)
  - An existing Pinecone Index name or a name for a new one (the script can create it)

- **Google AI API Key**:
  - An API key with access to Gemini models (e.g., from Google AI Studio or a Google Cloud Project with Vertex AI enabled)

- **Weights & Biases Account** (Optional, if using monitoring):
  - API Key
  - Project Name

- **AWS Account & AWS CLI** (Optional, for future cloud deployment):
  - Configured with necessary permissions if you plan to deploy to AWS later

## Setup and Installation (Local)

### 1. Clone the Repository

```bash
git clone https://github.com/YOUR_GITHUB_USERNAME/YOUR_REPOSITORY_NAME.git
cd YOUR_REPOSITORY_NAME
```

### 2. Create and Activate a Python Virtual Environment

**On macOS/Linux:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**On Windows:**
```bash
python -m venv .venv
.\.venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Up Environment Variables

Create a file named `.env` in the root of the project directory. You can copy `.env.example` (if provided in the repository) and rename it to `.env`.

**IMPORTANT**: The `.env` file should NEVER be committed to Git. Ensure it's listed in your `.gitignore` file.

Add your API keys and configuration to the `.env` file. See `.env.example` for required variables:

```env
# Example content for .env (replace with your actual values)
GOOGLE_API_KEY="YOUR_GOOGLE_AI_API_KEY_HERE"
PINECONE_API_KEY="YOUR_PINECONE_API_KEY_HERE"
PINECONE_ENVIRONMENT="your-pinecone-region-e.g.-us-east-1"
PINECONE_INDEX_NAME="your-chosen-pinecone-index-name"
WANDB_API_KEY="YOUR_WANDB_API_KEY_HERE" # Optional
WANDB_PROJECT_NAME="your-wandb-project-name" # Optional, e.g., gemini-doc-assistant
```

### 5. Initial Document Setup (for Pinecone Population)

The application is designed to populate the Pinecone index if it's new/empty and PDF documents are found in the `docs/` directory during startup.

- Place a few sample PDF files in the `docs/` directory for initial testing and index population
- **Note**: For a large number of documents, a separate, dedicated ingestion script is recommended

## Running the Application Locally

### 1. API Backend (main_api.py)

This provides the core Q&A functionality via an API.

1. Ensure your `.env` file is configured
2. Run the FastAPI application using Uvicorn:

```bash
uvicorn main_api:app --reload --port 8000
```

- The API will be accessible at `http://127.0.0.1:8000`
- Interactive API documentation (Swagger UI) will be available at `http://127.0.0.1:8000/docs`

### 2. Streamlit UI (ui_app.py)

This provides a web interface for uploading PDFs and asking questions.

1. Ensure your `.env` file is configured
2. Run the Streamlit application:

```bash
streamlit run ui_app.py
```

- The UI will typically be accessible at `http://localhost:8501` (Streamlit will show the exact URL)

## Docker Usage

### 1. Build the Docker Image

The Dockerfile should be configured to run either `main_api.py` or `ui_app.py`. Adjust the CMD instruction in the Dockerfile as needed.

```bash
docker build -t gemini-doc-assistant-app .
```

### 2. Run the Docker Container (Local)

Pass environment variables to the container at runtime.

**Example for main_api.py (API on port 8000):**

```bash
docker run -p 8000:8000 \
  -e GOOGLE_API_KEY="YOUR_GOOGLE_AI_API_KEY_HERE" \
  -e PINECONE_API_KEY="YOUR_PINECONE_API_KEY_HERE" \
  -e PINECONE_ENVIRONMENT="your-pinecone-region-e.g.-us-east-1" \
  -e PINECONE_INDEX_NAME="your-chosen-pinecone-index-name" \
  -e WANDB_API_KEY="YOUR_WANDB_API_KEY_HERE" \
  -e WANDB_PROJECT_NAME="your-wandb-project-name" \
  gemini-doc-assistant-app
```

Access the API at `http://localhost:8000/docs`.

**Example for ui_app.py (UI on port 8501):**
(Ensure Dockerfile CMD is `streamlit run ui_app.py --server.port 8501 --server.address 0.0.0.0`)

```bash
docker run -p 8501:8501 \
  -e GOOGLE_API_KEY="YOUR_GOOGLE_AI_API_KEY_HERE" \
  -e PINECONE_API_KEY="YOUR_PINECONE_API_KEY_HERE" \
  -e PINECONE_ENVIRONMENT="your-pinecone-region-e.g.-us-east-1" \
  -e PINECONE_INDEX_NAME="your-chosen-pinecone-index-name" \
  -e WANDB_API_KEY="YOUR_WANDB_API_KEY_HERE" \
  -e WANDB_PROJECT_NAME="your-wandb-project-name" \
  gemini-doc-assistant-app
```

Access the UI at `http://localhost:8501`.

## Weights & Biases Monitoring

If configured, the application logs interactions (queries, answers, processing times, errors) to your specified Weights & Biases project.

Monitor application performance and usage on your W&B dashboard.

## File Upload Feature (Streamlit UI)

The Streamlit UI (`ui_app.py`) allows users to upload PDF files.

- Uploaded PDFs are processed and their content is added to the shared Pinecone index
- **Note for Public Hosting**: In the current default setup, all users query a knowledge base augmented by all documents uploaded by any user. For data isolation in a multi-user public application, features like Pinecone namespaces and user authentication would be required.

## Troubleshooting

- **Environment Variables**: Ensure `.env` is correctly formatted and all required variables are present. Values loaded by the script can be verified with print statements if issues persist.
- **API Key Issues**: Double-check that all API keys are correct and have the necessary permissions.
- **Docker Issues**: Ensure Docker Desktop is running. Check `docker build` and `docker run` command outputs for errors. Use `docker logs <container_id>` for runtime errors.

## Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

## License

This project is licensed under the MIT License. (Consider adding a LICENSE file with the MIT License text)
